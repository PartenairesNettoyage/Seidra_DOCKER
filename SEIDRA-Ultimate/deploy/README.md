# D√©ploiement SEIDRA Ultimate

Ce r√©pertoire contient les manifestes Helm et les outils n√©cessaires pour d√©ployer la plateforme sur un cluster Kubernetes de staging ou de production. Les images utilis√©es proviennent des releases officielles publi√©es sur le registre `ghcr.io/seidra`.

## Pr√©-requis

- Un cluster Kubernetes accessible (kubeconfig configur√©) et un namespace d√©di√© (`seidra-staging` conseill√©).
- Helm 3.11+ install√© localement.
- Acc√®s en lecture au registre GitHub Container Registry (GHCR) et variables d'environnement `GHCR_TOKEN`/`GHCR_USERNAME` si l'espace est priv√©.
- Secrets Kubernetes d√©j√† cr√©√©s pour les mots de passe (PostgreSQL, Redis, MinIO, etc.).
- Base de donn√©es PostgreSQL provisionn√©e (g√©r√©e via `helm install postgresql` ou service manag√©) et migrations Alembic appliqu√©es.

## Validation continue : job `helm-dry-run`

Le workflow GitHub Actions `Ultimate CI` embarque un job `helm-dry-run` qui valide automatiquement le chart Helm avant chaque push/PR¬†:

1. Construction des images Docker backend et frontend avec `docker buildx` et tag GHCR `ghcr.io/<organisation>/ultimate-*-:${GITHUB_SHA}` (push d√©sactiv√©, les images sont charg√©es localement pour Kind).
2. Cr√©ation d'un cluster √©ph√©m√®re `kind` (`seidra-ci`) et import des deux images avec `kind load docker-image`.
3. Ex√©cution de `helm dependency update`, `helm lint` puis `helm upgrade --install --dry-run --debug deploy/helm` afin de g√©n√©rer les manifests complets.
4. V√©rification automatique que les ressources critiques (ConfigMap `seidra-config` et Secret `seidra-secrets`) sont pr√©sentes dans le rendu.
5. Publication des journaux (`backend-build.log`, `frontend-build.log`, `helm-dry-run.log`) dans l'artefact CI `helm-dry-run-logs` pour audit.

> ‚ÑπÔ∏è Les param√®tres Helm inject√©s dans le job positionnent `image.repository` sur `ghcr.io/<organisation>` et `image.tag` sur le SHA Git en cours, garantissant que les manifests r√©f√©rencent les images fra√Æchement construites.

### Dry-run manuel

Pour reproduire localement la v√©rification CI¬†:

```bash
export SEIDRA_REGISTRY="ghcr.io/<organisation>/<repo>"
export SEIDRA_TAG="dryrun-$(date +%s)"

# Construire et charger les images dans Docker
docker buildx build . \
  --file backend/Dockerfile \
  --platform linux/amd64 \
  --tag "${SEIDRA_REGISTRY}/ultimate-backend:${SEIDRA_TAG}" \
  --load

docker buildx build frontend \
  --file frontend/Dockerfile \
  --platform linux/amd64 \
  --tag "${SEIDRA_REGISTRY}/ultimate-frontend:${SEIDRA_TAG}" \
  --load

# Cr√©er un cluster Kind √©ph√©m√®re et lui injecter les images
kind create cluster --name seidra-ci --wait 120s
kind load docker-image --name seidra-ci "${SEIDRA_REGISTRY}/ultimate-backend:${SEIDRA_TAG}"
kind load docker-image --name seidra-ci "${SEIDRA_REGISTRY}/ultimate-frontend:${SEIDRA_TAG}"

# V√©rifier le chart Helm en mode dry-run + debug
helm dependency update deploy/helm
helm lint deploy/helm
helm upgrade --install seidra-ultimate deploy/helm \
  --namespace seidra-dryrun \
  --create-namespace \
  --set image.repository="${SEIDRA_REGISTRY}" \
  --set image.tag="${SEIDRA_TAG}" \
  --dry-run --debug | tee deploy/helm/helm-dry-run.log

# Nettoyer le cluster de test
kind delete cluster --name seidra-ci
```

Le fichier `deploy/helm/helm-dry-run.log` permet ensuite de v√©rifier la pr√©sence des ressources attendues (`ConfigMap`, `Secret`, `Deployments`, etc.).

## D√©ploiement staging (bout-en-bout)

1. Authentifier Helm/Kubernetes sur le cluster de staging.
2. Ex√©cuter le script [`scripts/deploy-staging.sh`](../scripts/deploy-staging.sh) afin de pr√©parer les valeurs et lancer `helm upgrade --install` avec les images GHCR de la derni√®re release.
3. V√©rifier les pods et l'exposition HTTP via `kubectl get pods -n seidra-staging` et `kubectl get ing -n seidra-staging`.
4. D√©clencher la g√©n√©ration initiale d'assets via l'API (`/api/generation/health`) pour s'assurer que les workers Celery s'enregistrent correctement.

Exemple d'ex√©cution manuelle sans script¬†:

```bash
helm upgrade --install seidra-ultimate ./helm \
  --namespace seidra-staging --create-namespace \
  --set image.tag=v1.4.2 \
  --set backend.replicaCount=2 \
  --set worker.replicaCount=2 \
  --set env.SEIDRA_DATABASE_URL="postgresql+asyncpg://user:pass@postgres:5432/seidra"
```

## Gestion des versions & rollback

Le chart Helm `seidra-ultimate` suit la s√©mantique suivante¬†:

- `Chart.yaml` ‚Üí version du chart (ex¬†: `0.1.0`) utilis√©e pour tracer les changements d'infra (templates, d√©pendances).
- `appVersion` ‚Üí version applicative align√©e sur la release GHCR (ex¬†: `1.4.2`).
- L'image Docker par d√©faut est `ghcr.io/seidra/ultimate-backend:<tag>` et doit √™tre synchronis√©e avec `appVersion`.

### Artefacts Python packag√©s

- Le `pyproject.toml` embarque d√©sormais une d√©tection automatique des modules `backend*` via `setuptools`. Un `pip wheel .` lanc√© √† la racine du d√©p√¥t g√©n√®re donc une roue `seidra_ultimate-<version>.whl` contenant l‚Äôint√©gralit√© du backend.
- Pour les pipelines CI/CD hors connexion, conserver ce wheel (et ceux des d√©pendances) dans un cache d‚Äôartefacts afin de garantir la reproductibilit√© des d√©ploiements.

### Strat√©gie de rollback Helm

1. Lister les r√©visions¬†: `helm history seidra-ultimate -n seidra-staging`.
2. S√©lectionner la r√©vision souhait√©e (par exemple `3`) et ex√©cuter¬†: `helm rollback seidra-ultimate 3 -n seidra-staging`.
3. V√©rifier que les nouveaux pods sont pr√™ts puis purger l'ancienne release si n√©cessaire (`helm uninstall`).

> üí° **Astuce**¬†: conserver les charts packag√©s (`helm package deploy/helm`) dans un bucket ou un artifact store pour faciliter un rollback m√™me si le d√©p√¥t Git n'est pas accessible.

### Migrations de base de donn√©es

Les migrations Alembic sont orchestr√©es via le job Kubernetes `ultimate-migrate` d√©clench√© lors du d√©ploiement.

- Pour appliquer une migration en avant¬†: `kubectl logs job/ultimate-migrate -n seidra-staging` doit indiquer `Upgrade successful`.
- En cas de rollback applicatif, ex√©cuter manuellement la migration inverse¬†:

```bash
kubectl create job --from=cronjob/ultimate-migrations ultimate-migrate-rollback \
  -n seidra-staging --env="ALEMBIC_COMMAND=downgrade -1"
```

- Documenter le num√©ro de r√©vision Alembic (`alembic_version` dans PostgreSQL) apr√®s chaque d√©ploiement pour savoir jusqu'o√π revenir.

### Synchronisation chart ‚Üî migrations

- Toujours taguer le chart Helm avec un num√©ro de version incr√©mental √† chaque modification de templates.
- Associer la r√©vision Alembic cible (`backend/alembic/versions/<timestamp>_*.py`) √† la release GHCR dans les notes de version.
- Les releases d'urgence doivent respecter la s√©quence¬†: rollback Helm ‚Üí rollback migrations (si n√©cessaire) ‚Üí v√©rification de l'√©tat (`/api/system/health`).

## Surveillances post-d√©ploiement

- `kubectl get events -n seidra-staging --sort-by=.metadata.creationTimestamp`
- Tableaux de bord Grafana (`monitoring/grafana`) pour la consommation GPU, CPU et les files Celery.
- Alertes Prometheus sur les pods `backend`, `worker` et `frontend`.
- Pile d'observabilit√© autonome d√©crite ci-dessous.

### Stack Prometheus / Grafana / Loki

Une stack compl√®te est fournie pour la supervision temps r√©el¬†:

- **Docker Compose**¬†: le fichier [`deploy/docker/monitoring.yml`](docker/monitoring.yml) installe Prometheus, Grafana, Loki et Promtail configur√©s avec les tableaux de bord du d√©p√¥t. D√©marrer l'ensemble via¬†:

  ```bash
  docker compose -f deploy/docker/monitoring.yml up -d
  ```

  Les volumes persistants (`prometheus-data`, `grafana-data`, `loki-data`) assurent la conservation des m√©triques et journaux. Les param√®tres Grafana (`GRAFANA_ADMIN_USER`, `GRAFANA_ADMIN_PASSWORD`) peuvent √™tre surcharg√©s via l'environnement.

- **Kubernetes**¬†: le r√©pertoire [`deploy/k8s/monitoring`](k8s/monitoring) fournit des valeurs Helm pr√™tes √† l'emploi pour Prometheus, Grafana et Loki. Elles r√©utilisent la configuration de `monitoring/` (alerting, dashboards) via des ConfigMaps. Exemple d'installation¬†:

  ```bash
  # Namespace d√©di√©
  kubectl create namespace observability

  # Prometheus
  helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
  helm upgrade --install prometheus prometheus-community/prometheus \
    --namespace observability \
    -f deploy/k8s/monitoring/values-prometheus.yaml

  # Loki
  helm repo add grafana https://grafana.github.io/helm-charts
  helm upgrade --install loki grafana/loki-stack \
    --namespace observability \
    -f deploy/k8s/monitoring/values-loki.yaml

  # Grafana (dashboards & alerting pr√©-charg√©s)
  helm upgrade --install grafana grafana/grafana \
    --namespace observability \
    -f deploy/k8s/monitoring/values-grafana.yaml
  ```

Consultez `monitoring/README.md` pour l'inventaire des m√©triques, des alertes unifi√©es et des points d'acc√®s.

## R√©f√©rences

- [Helm documentation](https://helm.sh/docs/)
- [GitHub Container Registry](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry)
