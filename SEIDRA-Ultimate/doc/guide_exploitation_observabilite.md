# Guide d'exploitation - Observabilit√© SEIDRA Ultimate

## 1. Objectifs

Ce guide d√©crit les proc√©dures quotidiennes pour exploiter la stack Prometheus / Grafana / Loki de SEIDRA Ultimate¬†:

- Surveiller la sant√© des services backend / workers IA
- Anticiper les incidents GPU / CPU
- Investiguer les lenteurs de g√©n√©ration
- Assurer la tra√ßabilit√© des notifications critiques persist√©es en base

## 2. Architecture de supervision

```
+----------------+      scrape       +----------------+      dashboards      +----------------+
| Prometheus     | <---------------- | Services SEIDRA| -------------------> | Grafana        |
+----------------+                   +----------------+ <------------------  +----------------+
       ^   ^                                                          logs / traces
       |   |                                                           |
       |   +----- Alertes vers Grafana (unified alerting)              v
       |                                                              +----------------+
       +---------------------- Loki / Promtail ----------------------> | Tempo / Loki   |
                                                                      +----------------+
```

- **Prometheus** collecte les m√©triques expos√©es sur `/metrics`.
- **Grafana** affiche les dashboards et porte les r√®gles d'alerte (CPU, GPU, latence).
- **Loki / Promtail** centralisent les journaux des conteneurs.
- **Tempo** (optionnel) stocke les traces distribu√©es.

## 3. Seuils d'alerte cl√©s

| Composant | Seuil | Source | Rem√©diation |
|-----------|-------|--------|-------------|
| CPU backend/worker | > 90¬†% sur 5 min | `seidra_system_cpu_percent` | V√©rifier les jobs Celery, envisager un scale-out (`kubectl scale deployment seidra-worker --replicas=3`). |
| Temp√©rature GPU | ‚â• 85¬†¬∞C | `seidra_gpu_temperature_celsius` | V√©rifier la ventilation, basculer en mode d√©grad√©, replanifier les jobs non urgents. |
| Latence g√©n√©ration (p95) | > 30 s | `celery_task_runtime_seconds_bucket` | Inspecter les logs des workers via Loki, v√©rifier la saturation VRAM. |

Les notifications correspondantes sont persist√©es c√¥t√© backend (table `notifications`) et purg√©es automatiquement apr√®s `settings.notification_retention_days` jours.

### 3.1 Connecteurs de notifications externes

Pour int√©grer les alertes SEIDRA Ultimate avec vos outils d'astreinte existants, le backend peut pousser les notifications critiques vers Slack ou PagerDuty. Ces connecteurs sont d√©sactiv√©s par d√©faut et se pilotent via les variables d'environnement expos√©es dans `.env`.

**Webhook Slack**

- Activer le connecteur¬†: `SEIDRA_NOTIFICATIONS_SLACK__ENABLED=true`
- Renseigner l'URL du webhook entrant¬†: `SEIDRA_NOTIFICATIONS_SLACK__WEBHOOK_URL=https://hooks.slack.com/services/...`
- (Optionnel) Personnaliser le nom et l'emoji¬†: `SEIDRA_NOTIFICATIONS_SLACK__USERNAME`, `SEIDRA_NOTIFICATIONS_SLACK__ICON_EMOJI`
- Filtrer les niveaux propag√©s¬†: `SEIDRA_NOTIFICATIONS_SLACK__LEVELS=error,critical`

Chaque notification correspondant aux niveaux configur√©s est envoy√©e au format enrichi (titre, message, tags, m√©tadonn√©es JSON) dans le canal Slack cibl√©.

**PagerDuty Events API v2**

- Activer le connecteur¬†: `SEIDRA_NOTIFICATIONS_PAGERDUTY__ENABLED=true`
- Fournir la cl√© d'int√©gration (routing key)¬†: `SEIDRA_NOTIFICATIONS_PAGERDUTY__ROUTING_KEY=<cl√©>`
- Ajuster la source/identit√© affich√©e¬†: `SEIDRA_NOTIFICATIONS_PAGERDUTY__SOURCE`, `SEIDRA_NOTIFICATIONS_PAGERDUTY__CLIENT`
- Pr√©fixer les cl√©s de d√©duplication (optionnel)¬†: `SEIDRA_NOTIFICATIONS_PAGERDUTY__DEDUP_KEY_PREFIX=seidra-`
- Filtrer les niveaux propag√©s¬†: `SEIDRA_NOTIFICATIONS_PAGERDUTY__LEVELS=error,critical`

Le connecteur d√©clenche un √©v√©nement `trigger` sur l'Events API avec un r√©sum√© standardis√© (`[LEVEL] Titre`), la s√©v√©rit√© mapp√©e automatiquement (`error` ‚Üí `error`, `critical` ‚Üí `critical`, etc.) et les m√©tadonn√©es (tags, cat√©gorie, d√©tails suppl√©mentaires) en `custom_details` pour faciliter le diagnostic dans PagerDuty.

> üí° **Bonnes pratiques**¬†: stockez les cl√©s sensibles (webhook Slack, routing key PagerDuty) dans votre gestionnaire de secrets et alimentez les variables d'environnement via l'orchestrateur (Docker/Kubernetes) plut√¥t que de les committer en clair.

## 4. Routines quotidiennes

1. **Tour d'horizon Grafana**
   - Dashboard ¬´¬†SEIDRA Ultimate - Observabilit√©¬†¬ª¬†: v√©rifier les panels GPU/CPU/Jobs.
   - V√©rifier `Alerting > Alerts` pour s'assurer qu'aucune alerte critique n'est en cours.

2. **Logs & traces**
   - Utiliser l'explorateur Loki pour les erreurs `level="ERROR"` des services `backend`/`worker`.
   - Si une latence anormale est d√©tect√©e, corr√©ler avec les traces Tempo (`Explore > Tempo`).

3. **Notifications persist√©es**
   - Consulter `/api/system/notifications` ou l'UI d'administration pour v√©rifier les alertes critiques stock√©es.
   - Le job de purge int√©gr√© au `GenerationService` supprime les alertes critiques d√©passant la p√©riode de r√©tention.

4. **Capacit√© & pr√©visionnel**
   - Surveiller le panneau ¬´¬†Temps moyen de g√©n√©ration¬†¬ª et ¬´¬†File d'attente Celery¬†¬ª.
   - Si la file approche du seuil critique, planifier l'ajout de workers ou l'activation de jobs batch hors heures pleines.

## 5. Gestion d'incidents

### 5.1 GPU indisponible

1. Alerte ¬´¬†Temp√©rature GPU critique¬†¬ª ou ¬´¬†GPU offline¬†¬ª active.
2. V√©rifier la charge syst√®me via Grafana et la temp√©rature sur le panel GPU.
3. Consulter les logs Loki (`{compose_service="backend"}`) pour les erreurs CUDA.
4. Mettre en pause les jobs batch, red√©ployer `seidra-worker` si n√©cessaire, informer l'√©quipe SRE.

### 5.2 Latence IA prolong√©e

1. Alerte ¬´¬†Latence IA √©lev√©e¬†¬ª.
2. Examiner le panel ¬´¬†Dur√©e p95 des jobs¬†¬ª et les m√©triques GPU (VRAM, temp√©rature).
3. V√©rifier si des jobs longs (> 60 s) monopolisent les workers via Grafana / Flower.
4. Activer le mode d√©grad√© (API `/api/system/mode`) ou ajouter des ressources selon la criticit√©.

### 5.3 CPU satur√©

1. Alerte ¬´¬†CPU backend satur√©¬†¬ª.
2. Identifier les endpoints ou t√¢ches consommateurs via Loki (`{compose_service="backend"}` + `level="WARNING"`).
3. Augmenter temporairement les r√©plicas backend ou worker.
4. V√©rifier les limites de ressources Kubernetes et ajuster si besoin.

## 6. Bonnes pratiques

- Versionner toute modification de dashboard/alerting dans `monitoring/grafana/`.
- Tester les expressions Prometheus via la console (`http://prometheus:9090`) avant de les pousser en production.
- Conserver un historique des incidents et des notifications critiques (export CSV avant purge si besoin).
- Synchroniser les variables d'environnement (`SEIDRA_NOTIFICATION_RETENTION_DAYS`, `GRAFANA_ADMIN_PASSWORD`) avec le vault interne.

## 7. R√©f√©rences

- [Runbook d'incident](../monitoring/runbook.md)
- [Configuration Docker/Kubernetes](../deploy/README.md)
- [Documentation Grafana Alerting](https://grafana.com/docs/grafana/latest/alerting/)
- [Documentation Prometheus](https://prometheus.io/docs/introduction/overview/)
